{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce42b447-6b83-4303-ab24-5c4009c77470",
   "metadata": {},
   "source": [
    "# Tennis Match Report Generation\n",
    "\n",
    "**Goal:** Generate short, factual tennis match reports from structured match statistics.\n",
    "\n",
    "We compare three models:\n",
    "\n",
    "1. **T5 baseline** – pre-trained `t5-small` used out-of-the-box.\n",
    "2. **Fine-tuned T5** – `t5-small` fine-tuned on 40 human-written reports.\n",
    "3. **GPT-4.1-mini** – API model used as a strong reference.\n",
    "\n",
    "We evaluate all models on the same 10 test matches using:\n",
    "- ROUGE\n",
    "- Sentence-level cosine similarity\n",
    "- An LLM-as-a-judge evaluation (accuracy, completeness, consistency, clarity, overall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dfbe77-ecb0-4eaa-a307-d11eafbf9b36",
   "metadata": {},
   "source": [
    "## 1. Data and task definition\n",
    "\n",
    "We start from a small custom dataset with **50 tennis matches**.  \n",
    "For each match we have:\n",
    "- structured statistics (aces, double faults, first-serve %, break points, etc.)\n",
    "- a short human-written report.\n",
    "\n",
    "We split the data into **40 training** and **10 test** matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9426f2f-80e7-484d-bcc4-badbddebbd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (50, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>round</th>\n",
       "      <th>surface</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>score</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>...</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian Open</td>\n",
       "      <td>R16</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>6-0 6-0 6-3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>You are a sports journalist. Write a short, fa...</td>\n",
       "      <td>Novak Djokovic dominated Adrian Mannarino 6-0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tourney_name round surface     winner_name        loser_name  \\\n",
       "0  Australian Open   R16    Hard  Novak Djokovic  Adrian Mannarino   \n",
       "\n",
       "         score  winner_rank  loser_rank  w_ace  w_df  ...  w_bpFaced  l_ace  \\\n",
       "0  6-0 6-0 6-3          1.0        19.0   17.0   5.0  ...        3.0    1.0   \n",
       "\n",
       "   l_df  l_1stIn  l_1stWon  l_2ndWon  l_bpSaved  l_bpFaced  \\\n",
       "0   0.0     34.0      17.0       8.0        4.0       11.0   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  You are a sports journalist. Write a short, fa...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Novak Djokovic dominated Adrian Mannarino 6-0,...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full cleaned dataset (50 matches)\n",
    "df_full = pd.read_csv(\"data/tennis_matches_for_human_reports_50_clean.tsv\", sep=\"\\t\")\n",
    "print(\"Full dataset shape:\", df_full.shape)\n",
    "\n",
    "df_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185b0a2-cfc5-4cb9-92b2-5b6d8709ccdc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Below we load the pre-split training and test sets (40 train, 10 test).\n",
    "Each row already contains:\n",
    "- `input_text`: prompt + match statistics\n",
    "- `target_text`: human-written reference report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef79a7e3-b10d-40c0-92de-e6056d96d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 40\n",
      "Test samples: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a sports journalist. Write a short, fa...</td>\n",
       "      <td>The fifth seed and 2021 titlist continued his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a sports journalist. Write a short, fa...</td>\n",
       "      <td>The Italian reached the last eight at a major ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  You are a sports journalist. Write a short, fa...   \n",
       "1  You are a sports journalist. Write a short, fa...   \n",
       "\n",
       "                                         target_text  \n",
       "0  The fifth seed and 2021 titlist continued his ...  \n",
       "1  The Italian reached the last eight at a major ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
    "test_df  = pd.read_csv(\"data/test.tsv\",  sep=\"\\t\")\n",
    "\n",
    "print(\"Train samples:\", len(train_df))\n",
    "print(\"Test samples:\",  len(test_df))\n",
    "\n",
    "test_df[[\"input_text\", \"target_text\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3c9f3-17b2-4134-a497-a9064bfe885c",
   "metadata": {},
   "source": [
    "## 2. Baseline model: T5-small\n",
    "\n",
    "As a simple baseline we use the pre-trained `t5-small` model **without any fine-tuning** on our data.\n",
    "We feed the `input_text` (prompt + stats) and let the model generate a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7375eef0-9eb1-4266-aa5c-799e84bd44f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llmproj/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce63a64-bd71-4aac-ba58-262ebe82ee3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>t5_baseline_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The fifth seed and 2021 titlist continued his ...</td>\n",
       "      <td>: 36.0 - 2nd serve points won: 14.0. Break poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Italian reached the last eight at a major ...</td>\n",
       "      <td>: 3.0 - Double faults: 0.0, 1st serve in: 50.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lorenzo Musetti delivered arguably the Grand S...</td>\n",
       "      <td>: 63.0 - 1st serve points won: 29.0- Break poi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         target_text  \\\n",
       "0  The fifth seed and 2021 titlist continued his ...   \n",
       "1  The Italian reached the last eight at a major ...   \n",
       "2  Lorenzo Musetti delivered arguably the Grand S...   \n",
       "\n",
       "                                  t5_baseline_output  \n",
       "0  : 36.0 - 2nd serve points won: 14.0. Break poi...  \n",
       "1  : 3.0 - Double faults: 0.0, 1st serve in: 50.0...  \n",
       "2  : 63.0 - 1st serve points won: 29.0- Break poi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load baseline T5 model (unchanged t5-small)\n",
    "baseline_model_name = \"t5-small\"\n",
    "baseline_tokenizer = T5TokenizerFast.from_pretrained(baseline_model_name)\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained(baseline_model_name)\n",
    "\n",
    "baseline_model.eval()\n",
    "\n",
    "def generate_t5_baseline_report(text, max_input_len=256, max_output_len=180):\n",
    "    \"\"\"Generate a report using the untuned T5-small baseline.\"\"\"\n",
    "    inputs = baseline_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_len,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = baseline_model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_output_len,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "\n",
    "    return baseline_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate baseline reports for all test samples\n",
    "baseline_outputs = [generate_t5_baseline_report(t) for t in test_df[\"input_text\"]]\n",
    "test_df[\"t5_baseline_output\"] = baseline_outputs\n",
    "\n",
    "test_df[[\"target_text\", \"t5_baseline_output\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d63d8f-9bb8-41d8-803d-21751483a537",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Example match: baseline output\n",
    "\n",
    "Below we show one full example (match 1) with:\n",
    "- input prompt + stats\n",
    "- human reference report\n",
    "- baseline T5 report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e92273-e83e-4312-a362-ec46ee153ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INPUT TEXT ===\n",
      "You are a sports journalist. Write a short, factual tennis match report in MAXIMUM 3 sentences.\n",
      "Use ONLY the information from the stats below. Do NOT invent any extra facts or numbers.\n",
      "\n",
      "Tournament: Wimbledon\n",
      "Round: R16\n",
      "Surface: Grass\n",
      "\n",
      "Winner: Lorenzo Musetti (rank 25.0)\n",
      "Loser: Giovanni Mpetshi Perricard (rank 58.0)\n",
      "Score: 4-6 6-3 6-3 6-2\n",
      "\n",
      "Winner stats:\n",
      "- Aces: 3.0\n",
      "- Double faults: 0.0\n",
      "- 1st serve in: 63.0\n",
      "- 1st serve points won: 50.0\n",
      "- 2nd serve points won: 21.0\n",
      "- Break points saved: 0.0 out of 1.0\n",
      "\n",
      "Loser stats:\n",
      "- Aces: 10.0\n",
      "- Double faults: 8.0\n",
      "- 1st serve in: 70.0\n",
      "- 1st serve points won: 47.0\n",
      "- 2nd serve points won: 20.0\n",
      "- Break points saved: 10.0 out of 15.0 \n",
      "\n",
      "=== TARGET TEXT ===\n",
      "The Italian reached the last eight at a major for the first time on Monday at Wimbledon, where he ended the run of French lucky loser Giovanni Mpetshi Perricard with a 4-6, 6-3, 6-3, 6-2 victory.\n",
      "Mpetshi Perricard was celebrating his 21st birthday and entered the match high in confidence. The big-serving Frenchman defeated Sebastian Korda, Yoshihito Nishioka and Emil Ruusuvuori en route to his first fourth-round appearance at a major, hitting 105 aces across his first three matches.\n",
      "The Lyon champion was unable to fire at his best level against Musetti in the pair’s first Lexus ATP Head2Head meeting. The 25th seed broke Mpetshi Perricard’s serve five times and was the more consistent in the baseline exchanges, committing just eight unforced errors compared to 42 from his opponent. \n",
      "\n",
      "=== T5 BASELINE OUTPUT ===\n",
      ": 3.0 - Double faults: 0.0, 1st serve in: 50.0  2nd serve points won: 21.0. Break points saved: 10.0 out of 15.0 Loser stats : 1.\n"
     ]
    }
   ],
   "source": [
    "example_idx = 1  # you can change this to 1 or 2 in the presentation\n",
    "\n",
    "row = test_df.iloc[example_idx]\n",
    "\n",
    "print(\"=== INPUT TEXT ===\")\n",
    "print(row[\"input_text\"], \"\\n\")\n",
    "print(\"=== TARGET TEXT ===\")\n",
    "print(row[\"target_text\"], \"\\n\")\n",
    "print(\"=== T5 BASELINE OUTPUT ===\")\n",
    "print(row[\"t5_baseline_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78246ca9-c412-48df-be81-d3ffc4fcc3b6",
   "metadata": {},
   "source": [
    "## 3. Fine-tuned T5 model\n",
    "\n",
    "We fine-tuned `t5-small` on the 40 training matches (input_text → target_text).\n",
    "The training code lives in a separate notebook (`t5_training.ipynb`).\n",
    "Here we simply load the saved model and generate reports on the 10 test matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38344861-0113-4c26-b380-a078caf7b571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>t5_baseline_output</th>\n",
       "      <th>t5_finetuned_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The fifth seed and 2021 titlist continued his ...</td>\n",
       "      <td>: 36.0 - 2nd serve points won: 14.0. Break poi...</td>\n",
       "      <td>Daniil Medvedev beat Nuno Borges 6-0, 6-1, 6-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Italian reached the last eight at a major ...</td>\n",
       "      <td>: 3.0 - Double faults: 0.0, 1st serve in: 50.0...</td>\n",
       "      <td>Lorenzo Musetti beat Giovanni Mpetshi Perricar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lorenzo Musetti delivered arguably the Grand S...</td>\n",
       "      <td>: 63.0 - 1st serve points won: 29.0- Break poi...</td>\n",
       "      <td>Lorenzo Musetti beat Taylor Fritz 3-6, 7-6(5),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         target_text  \\\n",
       "0  The fifth seed and 2021 titlist continued his ...   \n",
       "1  The Italian reached the last eight at a major ...   \n",
       "2  Lorenzo Musetti delivered arguably the Grand S...   \n",
       "\n",
       "                                  t5_baseline_output  \\\n",
       "0  : 36.0 - 2nd serve points won: 14.0. Break poi...   \n",
       "1  : 3.0 - Double faults: 0.0, 1st serve in: 50.0...   \n",
       "2  : 63.0 - 1st serve points won: 29.0- Break poi...   \n",
       "\n",
       "                                 t5_finetuned_output  \n",
       "0  Daniil Medvedev beat Nuno Borges 6-0, 6-1, 6-3...  \n",
       "1  Lorenzo Musetti beat Giovanni Mpetshi Perricar...  \n",
       "2  Lorenzo Musetti beat Taylor Fritz 3-6, 7-6(5),...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fine-tuned T5 model from disk\n",
    "ft_model_path = \"./tiny_t5_tennis_report_model_clean\"\n",
    "\n",
    "ft_tokenizer = T5TokenizerFast.from_pretrained(ft_model_path)\n",
    "ft_model     = T5ForConditionalGeneration.from_pretrained(ft_model_path)\n",
    "ft_model.eval()\n",
    "\n",
    "def generate_t5_finetuned_report(text, max_input_len=256, max_output_len=180):\n",
    "    \"\"\"Generate a report using the fine-tuned T5 model.\"\"\"\n",
    "    inputs = ft_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_len,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = ft_model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_output_len,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "\n",
    "    return ft_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate fine-tuned outputs for all test samples\n",
    "ft_outputs = [generate_t5_finetuned_report(t) for t in test_df[\"input_text\"]]\n",
    "test_df[\"t5_finetuned_output\"] = ft_outputs\n",
    "\n",
    "test_df[[\"target_text\", \"t5_baseline_output\", \"t5_finetuned_output\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae11541-3c13-49e9-9467-d8a13b611817",
   "metadata": {},
   "source": [
    "### Example match: fine-tuned T5 vs baseline\n",
    "\n",
    "We now compare the same match for baseline T5 and fine-tuned T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486509d5-0f66-4707-9422-da14c70718d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET TEXT ===\n",
      "The Italian reached the last eight at a major for the first time on Monday at Wimbledon, where he ended the run of French lucky loser Giovanni Mpetshi Perricard with a 4-6, 6-3, 6-3, 6-2 victory.\n",
      "Mpetshi Perricard was celebrating his 21st birthday and entered the match high in confidence. The big-serving Frenchman defeated Sebastian Korda, Yoshihito Nishioka and Emil Ruusuvuori en route to his first fourth-round appearance at a major, hitting 105 aces across his first three matches.\n",
      "The Lyon champion was unable to fire at his best level against Musetti in the pair’s first Lexus ATP Head2Head meeting. The 25th seed broke Mpetshi Perricard’s serve five times and was the more consistent in the baseline exchanges, committing just eight unforced errors compared to 42 from his opponent. \n",
      "\n",
      "=== T5 BASELINE OUTPUT ===\n",
      ": 3.0 - Double faults: 0.0, 1st serve in: 50.0  2nd serve points won: 21.0. Break points saved: 10.0 out of 15.0 Loser stats : 1. \n",
      "\n",
      "=== T5 FINETUNED OUTPUT ===\n",
      "Lorenzo Musetti beat Giovanni Mpetshi Perricard to reach the final of the Wimbledon round at Wimbledon on Saturday. The defending champion was beaten 4-6, 6-3, 3:3 and 6-2 in the second round.\n"
     ]
    }
   ],
   "source": [
    "row = test_df.iloc[example_idx]\n",
    "\n",
    "print(\"=== TARGET TEXT ===\")\n",
    "print(row[\"target_text\"], \"\\n\")\n",
    "\n",
    "print(\"=== T5 BASELINE OUTPUT ===\")\n",
    "print(row[\"t5_baseline_output\"], \"\\n\")\n",
    "\n",
    "print(\"=== T5 FINETUNED OUTPUT ===\")\n",
    "print(row[\"t5_finetuned_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98e1c0-9c7e-4ba8-adb9-7d76de8e3750",
   "metadata": {},
   "source": [
    "## 4. GPT-4.1-mini as a strong reference model\n",
    "\n",
    "Finally, we query the GPT-4.1-mini API using the same `input_text` as prompt.\n",
    "We treat these reports as a strong reference system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc7006e-09f3-4a47-ad72-af30d9195196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>gpt41_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The fifth seed and 2021 titlist continued his ...</td>\n",
       "      <td>Daniil Medvedev defeated Nuno Borges 6-0, 6-1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         target_text  \\\n",
       "0  The fifth seed and 2021 titlist continued his ...   \n",
       "\n",
       "                                        gpt41_output  \n",
       "0  Daniil Medvedev defeated Nuno Borges 6-0, 6-1,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_gpt41mini(text):\n",
    "    \"\"\"Call GPT-4.1-mini with the full input_text prompt.\"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=text,\n",
    "    )\n",
    "    return resp.output[0].content[0].text\n",
    "\n",
    "gpt41_outputs = []\n",
    "for i, prompt in enumerate(test_df[\"input_text\"]):\n",
    "    out = generate_gpt41mini(prompt)\n",
    "    gpt41_outputs.append(out)\n",
    "    time.sleep(0.3)  # small pause for rate limiting\n",
    "\n",
    "test_df[\"gpt41_output\"] = gpt41_outputs\n",
    "\n",
    "test_df[[\"target_text\", \"gpt41_output\"]].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f29eb-a309-4c1f-b85d-8867631fcbab",
   "metadata": {},
   "source": [
    "### Example match: all three models\n",
    "\n",
    "We now show the same test match for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a87e020-4014-421a-99da-a4deb6d85549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET TEXT ===\n",
      "The Italian reached the last eight at a major for the first time on Monday at Wimbledon, where he ended the run of French lucky loser Giovanni Mpetshi Perricard with a 4-6, 6-3, 6-3, 6-2 victory.\n",
      "Mpetshi Perricard was celebrating his 21st birthday and entered the match high in confidence. The big-serving Frenchman defeated Sebastian Korda, Yoshihito Nishioka and Emil Ruusuvuori en route to his first fourth-round appearance at a major, hitting 105 aces across his first three matches.\n",
      "The Lyon champion was unable to fire at his best level against Musetti in the pair’s first Lexus ATP Head2Head meeting. The 25th seed broke Mpetshi Perricard’s serve five times and was the more consistent in the baseline exchanges, committing just eight unforced errors compared to 42 from his opponent. \n",
      "\n",
      "=== T5 BASELINE OUTPUT ===\n",
      ": 3.0 - Double faults: 0.0, 1st serve in: 50.0  2nd serve points won: 21.0. Break points saved: 10.0 out of 15.0 Loser stats : 1. \n",
      "\n",
      "=== T5 FINETUNED OUTPUT ===\n",
      "Lorenzo Musetti beat Giovanni Mpetshi Perricard to reach the final of the Wimbledon round at Wimbledon on Saturday. The defending champion was beaten 4-6, 6-3, 3:3 and 6-2 in the second round. \n",
      "\n",
      "=== GPT-4.1-MINI OUTPUT ===\n",
      "Lorenzo Musetti defeated Giovanni Mpetshi Perricard 4-6, 6-3, 6-3, 6-2 in the Wimbledon round of 16 on grass. Despite Perricard hitting 10 aces and saving 10 of 15 break points, his 8 double faults and lower break point resilience cost him the match. Musetti served clean with no double faults and improved after losing the first set, securing the win with consistent play.\n"
     ]
    }
   ],
   "source": [
    "row = test_df.iloc[example_idx]\n",
    "\n",
    "print(\"=== TARGET TEXT ===\")\n",
    "print(row[\"target_text\"], \"\\n\")\n",
    "\n",
    "print(\"=== T5 BASELINE OUTPUT ===\")\n",
    "print(row[\"t5_baseline_output\"], \"\\n\")\n",
    "\n",
    "print(\"=== T5 FINETUNED OUTPUT ===\")\n",
    "print(row[\"t5_finetuned_output\"], \"\\n\")\n",
    "\n",
    "print(\"=== GPT-4.1-MINI OUTPUT ===\")\n",
    "print(row[\"gpt41_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd280a-4772-4774-9392-5a47dfb153dd",
   "metadata": {},
   "source": [
    "## 5. Save combined test file with all model outputs\n",
    "\n",
    "For further analysis and for the report, we save a single TSV file containing:\n",
    "- basic match metadata,\n",
    "- the prompt (`input_text`),\n",
    "- the reference report,\n",
    "- outputs from all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bad9a61-fe6f-4793-afb6-b403aa41ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/test_with_all_models.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>round</th>\n",
       "      <th>surface</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>score</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>t5_baseline_output</th>\n",
       "      <th>t5_finetuned_output</th>\n",
       "      <th>gpt41_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Us Open</td>\n",
       "      <td>R16</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Daniil Medvedev</td>\n",
       "      <td>Nuno Borges</td>\n",
       "      <td>6-0 6-1 6-3</td>\n",
       "      <td>You are a sports journalist. Write a short, fa...</td>\n",
       "      <td>The fifth seed and 2021 titlist continued his ...</td>\n",
       "      <td>: 36.0 - 2nd serve points won: 14.0. Break poi...</td>\n",
       "      <td>Daniil Medvedev beat Nuno Borges 6-0, 6-1, 6-3...</td>\n",
       "      <td>Daniil Medvedev defeated Nuno Borges 6-0, 6-1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_name round surface      winner_name   loser_name        score  \\\n",
       "0      Us Open   R16    Hard  Daniil Medvedev  Nuno Borges  6-0 6-1 6-3   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  You are a sports journalist. Write a short, fa...   \n",
       "\n",
       "                                         target_text  \\\n",
       "0  The fifth seed and 2021 titlist continued his ...   \n",
       "\n",
       "                                  t5_baseline_output  \\\n",
       "0  : 36.0 - 2nd serve points won: 14.0. Break poi...   \n",
       "\n",
       "                                 t5_finetuned_output  \\\n",
       "0  Daniil Medvedev beat Nuno Borges 6-0, 6-1, 6-3...   \n",
       "\n",
       "                                        gpt41_output  \n",
       "0  Daniil Medvedev defeated Nuno Borges 6-0, 6-1,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns we really want in the \"all models\" file\n",
    "cols_to_keep = [\n",
    "    \"tourney_name\", \"round\", \"surface\",\n",
    "    \"winner_name\", \"loser_name\", \"score\",\n",
    "    \"input_text\", \"target_text\",\n",
    "    \"t5_baseline_output\",\n",
    "    \"t5_finetuned_output\",\n",
    "    \"gpt41_output\",\n",
    "]\n",
    "\n",
    "df_all = test_df[cols_to_keep].copy()\n",
    "df_all.to_csv(\"data/test_with_all_models.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Saved to data/test_with_all_models.tsv\")\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a631b8-39ca-405d-8192-1f6b85ea0bdc",
   "metadata": {},
   "source": [
    "## 6. Automatic evaluation\n",
    "\n",
    "We evaluate all three models on the 10 test matches using:\n",
    "\n",
    "- **ROUGE:** overlap between generated and reference n-grams.\n",
    "- **Cosine similarity:** sentence embeddings from `all-MiniLM-L6-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4031fe75-e66f-4f8b-8230-9937476c2ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>T5_baseline</th>\n",
       "      <th>T5_finetuned</th>\n",
       "      <th>GPT_4_1_mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  T5_baseline  T5_finetuned  GPT_4_1_mini\n",
       "0     rouge1        0.125         0.393         0.330\n",
       "1     rouge2        0.051         0.205         0.151\n",
       "2     rougeL        0.099         0.260         0.231\n",
       "3  rougeLsum        0.109         0.297         0.260"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "refs      = test_df[\"target_text\"].tolist()\n",
    "base_out  = test_df[\"t5_baseline_output\"].tolist()\n",
    "ft_out    = test_df[\"t5_finetuned_output\"].tolist()\n",
    "gpt_out   = test_df[\"gpt41_output\"].tolist()\n",
    "\n",
    "rouge_base = rouge.compute(predictions=base_out, references=refs, use_stemmer=True)\n",
    "rouge_ft   = rouge.compute(predictions=ft_out,   references=refs, use_stemmer=True)\n",
    "rouge_gpt  = rouge.compute(predictions=gpt_out,  references=refs, use_stemmer=True)\n",
    "\n",
    "summary_rouge = pd.DataFrame({\n",
    "    \"metric\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    \"T5_baseline\": [round(rouge_base[m], 3) for m in [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]],\n",
    "    \"T5_finetuned\": [round(rouge_ft[m], 3)   for m in [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]],\n",
    "    \"GPT_4_1_mini\": [round(rouge_gpt[m], 3)  for m in [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]],\n",
    "})\n",
    "summary_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103ecff9-144a-4286-bce0-16bd2171b51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cosine_baseline     0.338\n",
       "cosine_finetuned    0.783\n",
       "cosine_gpt          0.777\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model_st = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def cosine_scores(refs, preds):\n",
    "    emb_a = model_st.encode(refs, convert_to_tensor=True)\n",
    "    emb_b = model_st.encode(preds, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb_a, emb_b).diagonal().cpu().tolist()\n",
    "\n",
    "test_df[\"cosine_baseline\"] = cosine_scores(refs, base_out)\n",
    "test_df[\"cosine_finetuned\"] = cosine_scores(refs, ft_out)\n",
    "test_df[\"cosine_gpt\"] = cosine_scores(refs, gpt_out)\n",
    "\n",
    "summary_cosine = test_df[[\"cosine_baseline\", \"cosine_finetuned\", \"cosine_gpt\"]].mean().round(3)\n",
    "summary_cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcfc706-3bca-4cdb-a12e-1b8bf3364d5a",
   "metadata": {},
   "source": [
    "## 7. LLM-as-a-judge evaluation\n",
    "\n",
    "Finally, we ask GPT-4.1-mini to score each generated report on:\n",
    "\n",
    "- **accuracy** (facts correct, no hallucinations)\n",
    "- **completeness** (covers main aspects of the match)\n",
    "- **consistency** (internally coherent)\n",
    "- **clarity** (easy to read and understand)\n",
    "- **overall** (1–10 overall quality)\n",
    "\n",
    "Each score is on a 1–10 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fad797e-8e6e-47ed-9125-cbc40498a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm_score(reference_text, candidate_text, model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    Evaluates a candidate match report using an LLM.\n",
    "    Score categories: accuracy, completeness, consistency, clarity, overall (1–10).\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert tennis journalist and evaluation judge.\n",
    "Evaluate the candidate match report.\n",
    "\n",
    "REFERENCE REPORT:\n",
    "\\\"\\\"\\\"{reference_text}\\\"\\\"\\\"\n",
    "\n",
    "CANDIDATE REPORT:\n",
    "\\\"\\\"\\\"{candidate_text}\\\"\\\"\\\"\n",
    "\n",
    "Rate the candidate report from 1–10 in the following categories:\n",
    "- accuracy\n",
    "- completeness\n",
    "- consistency\n",
    "- clarity\n",
    "- overall\n",
    "\n",
    "Respond **ONLY** with a Python dictionary like this:\n",
    "{{\"accuracy\": x, \"completeness\": y, \"consistency\": z, \"clarity\": c, \"overall\": o}}\n",
    "    \"\"\"\n",
    "\n",
    "    # Call OpenAI\n",
    "    resp = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    raw_text = resp.output[0].content[0].text\n",
    "\n",
    "    # Versuch: das LLM Dictionary extrahieren\n",
    "    match = re.search(r\"\\{.*\\}\", raw_text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"LLM returned no dictionary! Raw output:\\n\" + raw_text)\n",
    "\n",
    "    dict_text = match.group(0)\n",
    "\n",
    "    # In echtes Python-Dict umwandeln\n",
    "    try:\n",
    "        scores = json.loads(dict_text)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"Could not parse JSON. Text was:\\n\" + dict_text)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0accc948-4b92-4223-b5c1-32db7e563b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model_with_llm(df, pred_column, n_samples=None, model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    Evaluates one prediction column against target_text using the LLM judge.\n",
    "    \n",
    "    df: DataFrame with columns 'target_text' and pred_column\n",
    "    pred_column: name of the column with model outputs\n",
    "    n_samples: if not None, evaluate only that many random samples\n",
    "    \"\"\"\n",
    "    if n_samples is not None:\n",
    "        sub = df.sample(n_samples, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        sub = df.reset_index(drop=True)\n",
    "    \n",
    "    all_scores = []\n",
    "    for i, (ref, cand) in enumerate(zip(sub[\"target_text\"], sub[pred_column]), start=1):\n",
    "        scores = llm_score(ref, cand, model_name=model_name)\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    scores_df = pd.DataFrame(all_scores)\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ea596be-a995-4ef1-93aa-7e94d54d022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falls dein Test-DataFrame anders heißt, hier anpassen\n",
    "df_test = pd.read_csv(\"data/test_with_all_models.tsv\", sep=\"\\t\")  # oder z.B. df_test = pd.read_csv(\"data/test_with_all_models.tsv\", sep=\"\\t\")\n",
    "\n",
    "scores_base = evaluate_model_with_llm(df_test, \"t5_baseline_output\", n_samples=None)\n",
    "scores_ft   = evaluate_model_with_llm(df_test, \"t5_finetuned_output\", n_samples=None)\n",
    "scores_gpt  = evaluate_model_with_llm(df_test, \"gpt41_output\",       n_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78708f60-e0bd-4eb0-9a1a-5f47a21b9b93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>T5_baseline</th>\n",
       "      <th>T5_finetuned</th>\n",
       "      <th>GPT_4.1_mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completeness</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>consistency</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clarity</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overall</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric  T5_baseline  T5_finetuned  GPT_4.1_mini\n",
       "0      accuracy          1.9           3.8           8.5\n",
       "1  completeness          1.2           2.5           6.0\n",
       "2   consistency          1.6           3.7           9.0\n",
       "3       clarity          1.2           5.2           8.2\n",
       "4       overall          1.3           3.6           7.3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_llm = pd.DataFrame({\n",
    "    \"metric\": [\"accuracy\", \"completeness\", \"consistency\", \"clarity\", \"overall\"],\n",
    "    \"T5_baseline\": scores_base.mean().values,\n",
    "    \"T5_finetuned\": scores_ft.mean().values,\n",
    "    \"GPT_4.1_mini\": scores_gpt.mean().values,\n",
    "})\n",
    "\n",
    "summary_llm = summary_llm.round(2)\n",
    "summary_llm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmproj)",
   "language": "python",
   "name": "llmproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
