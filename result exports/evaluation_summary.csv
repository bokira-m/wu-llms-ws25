Method,F1_Score,Cosine_Similarity
Fine-tuned (TinyLlama + LoRA),0.2034,0.1686
RAG (gemma2:2b),0.2024,0.2482
Baseline (TinyLlama-1.1B),0.1873,0.1568
Fine-tuned (Qwen2.5 + LoRA),0.129,0.1738
Baseline (Qwen2.5-1.5B),0.1222,0.1803

RAG_Generator,F1_Score,Cosine_Similarity,Precision,Recall,Avg_Time
gemma2:2b,0.2024,0.2482,0.1313,0.4933,7.56
tinyllama,0.1621,0.204,0.1027,0.4031,3.55
llama2,0.1196,0.1252,0.0781,0.2733,11.47

Embedding_Model,Dimension,Relevance,Top_Similarity,Eval_Time
all-mpnet-base-v2,768,0.4008,0.6634,19.75
paraphrase-multilingual-MiniLM-L12-v2,384,0.354,0.6947,2.0
all-MiniLM-L6-v2,384,0.3431,0.577,2.69
